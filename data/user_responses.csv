Timestamp,First_Name,Last_Name,Programming,Data_Analysis,ML_Projects,ML_Problem,NLP,Data_Pipeline,Sharing_Results,Git_Level,Presentation_Level,Reflection
2025-10-08 22:15:00,Ikramtakes43,Lovelace,"Python, SQL, basic OOP","EDA with pandas, joins, groupby; dashboards in Power BI","Churn prediction, credit-risk baseline",Binary classification with logistic regression and XGBoost,"Tokenization, embeddings, sentiment on reviews","ETL with Python, scheduled jobs",Dashboards + short write-ups; weekly demos,3,3,I like structured problems and quick iteration
2025-10-08 22:02:00,Ikramtakes3,Lovelace,"Python, SQL, basic OOP","EDA with pandas, joins, groupby; dashboards in Power BI","Churn prediction, credit-risk baseline",Binary classification with logistic regression and XGBoost,"Tokenization, embeddings, sentiment on reviews","ETL with Python, scheduled jobs",Dashboards + short write-ups; weekly demos,3,3,I like structured problems and quick iteration
2025-10-08 21:35:00,Ikramtakes2,Liko,Python and SQL,I clean data and visualize trends,I built a churn prediction model,classification and regression,yes,I use Airflow for ETL and automation,I create dashboards with Power BI,4,5,I enjoy solving problems and improving workflows
2025-10-07 17:30:00,Ikram,Liko,Python and SQL,I clean data and visualize trends,I built a churn prediction model,classification and regression,yes,I use Airflow for ETL and automation,I create dashboards with Power BI,4,5,I enjoy solving problems and improving workflows
2025-10-07 16:16:00,Alan,Turing,"Python, NumPy, scikit-learn","A/B tests, statistical summaries, visualization with matplotlib",Time-series forecasting for sales,Forecasting with Prophet and LightGBM,Basic NER and text cleaning,Batch pipelines; CSV → parquet; data validation,Notebooks + slides to explain assumptions,4,4,Strong at mathy tasks; want more production experience
2025-10-07 16:15:00,Ada,Lovelace,"Python, SQL, basic OOP","EDA with pandas, joins, groupby; dashboards in Power BI","Churn prediction, credit-risk baseline",Binary classification with logistic regression and XGBoost,"Tokenization, embeddings, sentiment on reviews","ETL with Python, scheduled jobs",Dashboards + short write-ups; weekly demos,3,3,I like structured problems and quick iteration
2025-10-07 13:32:30,TEST,CSV,Python,clean data,regression model,engineering,tokenisation,etl,dashboards,4,2,problem solving
2025-10-07 14:42:18,Tester,does tests,"I use python, hadoop and I have knowledge in AML ",,,,yes,,,2,5,
2025-10-07 14:51:05,Tester deux,does tests again,"I use python, hadoop and I have knowledge in AML ",eda ,,,yes,,,2,2,
2025-10-08 13:41:02,Victor,Chevallier,I use a lot of Python and C,I work with the raw data and i make dataframes with it,I used scikit-learn to evuluate the cahnce of survival of a person on the Titanic based on multiple factors,"I’d define churn, engineer key features, and train a model like XGBoost to predict and prevent customer loss.",Yes,I implemented a Python ETL for the french army from raw data to its analyze,"I create dashboards (superset, powerBI) and dataframes",3,3,"Communication skills, rigor, curioszty"
2025-10-08 14:56:20,Victor,Chevallier,"Test, python","Test, i do data engineering","Test, q-learning sckitilearn","Test, with a xgboost",Yes ,"Test, at army with data engineering",With dashboard on power query ,3,3,Communication and rigorousness
2025-10-08 15:08:06,Vivi,Cheval,SQL,SQL,SQL,SQL,SQL,SQL,SQL,3,3,SQL
2025-10-08 15:30:15,Victor,Chevallier,J'en ai marre,J'en ai marre,SQL,J'en ai marre,J'en ai marre,Data engineering ,J'en ai marre,3,3,J'en ai marre
2025-10-08 15:42:32,Vivi,marche bordel,marche bordel,marche bordel,marche bordel,marche bordel,SQL,marche bordel,dashboards,3,3,marche bordel
2025-10-08 16:02:55,SQL,SQL,SQL,SQL,SQL,SQL,SQL,SQL,SQL,3,3,SQL
2025-10-08 16:24:53,a,a,a,a,a,a,a,a,a,3,3,a
2025-10-08 16:42:15,gra,gra,gra,gra,gra,gra,gra,gra,gra,3,3,gra
2025-10-08 17:21:51,test,test,test,test,test,test,v,test,test,3,3,test
2025-10-09 12:29:27,Test,Gra,SQL,Vizualisation,Vizualisation,Vizualisation,Data Analyst,Vizualisation,Vizualisation,3,3,Vizualisation
2025-10-09 12:43:08,b,b,b,b,b,b,b,b,b,3,3,b
2025-10-09 12:48:44,v,v,v,v,v,v,v,v,v,3,3,v
2025-10-10 08:13:05,Corentin,Coffre,az,az,az,az,az,az,az,3,3,az
2025-10-10 08:25:41,Corentin,Coffre,"I specialize in Python with deep expertise in NLP libraries: transformers, spaCy, NLTK, Hugging Face. Also proficient in PyTorch for custom model architectures. Use SQL for data extraction.","For text data, I check corpus statistics, token distributions, vocabulary size. Analyze text length distributions, language detection, encoding issues. For tabular data, standard EDA with pandas and visualizations.","I have basic ML knowledge - logistic regression, random forests for classification. But my focus is on NLP-specific modeling with transformers and language models.","I would approach it as a classification problem. Extract text features from customer interactions if available. Use embeddings to capture semantic meaning. Try logistic regression baseline, then gradient boosting. But this is not my core expertise.","This is my core expertise. I have 5 years in NLP. Built multiple text classification systems with BERT, RoBERTa, and DistilBERT. Fine-tuned models for sentiment analysis, intent classification, and content moderation. Implemented named entity recognition with spaCy and transformer models. Created question-answering systems using T5 and BART. Built chatbots with GPT and dialogue transformers. Worked on machine translation and text summarization. Used tokenization, lemmatization, POS tagging extensively. Deployed models with FastAPI and Docker.",Limited experience. I focus on model development. Data engineers handle pipeline infrastructure in my team.,"I create model performance reports with precision, recall, F1-scores. Visualize confusion matrices and error analysis. Present to technical teams and explain model capabilities and limitations to product managers.",4,3,"Deep understanding of language models, transformers architecture, training techniques, and ability to fine-tune models for specific tasks."
