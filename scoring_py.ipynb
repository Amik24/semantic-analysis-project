{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDxeZwSNQIvG9JpLhTNcGg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amik24/semantic-analysis-project/blob/Ikram_notebooks/scoring_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rMHt93E-kUiE"
      },
      "outputs": [],
      "source": [
        "# code/scoring.py\n",
        "# ---------------------------------------------\n",
        "# Rôle : fonctions de scoring pour compétences et métiers.\n",
        "\n",
        "from typing import Dict, List, Literal\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sentence_transformers import util\n",
        "import torch\n",
        "\n",
        "# ---------- COMPETENCE SCORING (MAX vs AVG) ----------\n",
        "\n",
        "def compute_comp_scores(\n",
        "    user_emb: torch.Tensor,\n",
        "    comp_emb: torch.Tensor,\n",
        "    comp_ids: List[str],\n",
        "    comp_texts: List[str],\n",
        "    cid2block: Dict[str, str],\n",
        "    mode: Literal[\"max\", \"avg\"] = \"avg\"\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calcule un score de similarité pour CHAQUE compétence.\n",
        "    mode='max' : meilleur score parmi toutes les réponses (très sensible)\n",
        "    mode='avg' : moyenne des réponses -> profil unique (plus stable)\n",
        "    Retourne un DataFrame trié par 'Score' décroissant.\n",
        "    \"\"\"\n",
        "    if mode == \"max\":\n",
        "        S = util.cos_sim(user_emb, comp_emb)           # (n_inputs x n_comp)\n",
        "        scores = S.max(dim=0).values.cpu().numpy()\n",
        "    elif mode == \"avg\":\n",
        "        user_avg = user_emb.mean(dim=0, keepdim=True)  # (1 x d)\n",
        "        S = util.cos_sim(user_avg, comp_emb)           # (1 x n_comp)\n",
        "        scores = S.squeeze(0).cpu().numpy()\n",
        "    else:\n",
        "        raise ValueError(\"mode must be 'max' or 'avg'\")\n",
        "\n",
        "    comp_df = pd.DataFrame({\n",
        "        \"CompetencyID\":   comp_ids,\n",
        "        \"CompetencyText\": comp_texts,\n",
        "        \"BlockName\":      [cid2block[c] for c in comp_ids],\n",
        "        \"Score\":          scores\n",
        "    }).sort_values(\"Score\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "    return comp_df\n",
        "\n",
        "def block_coverage(comp_df: pd.DataFrame) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Score moyen par bloc (Series triée).\n",
        "    \"\"\"\n",
        "    return comp_df.groupby(\"BlockName\")[\"Score\"].mean().sort_values(ascending=False)\n",
        "\n",
        "# ---------- JOB SCORING (Top-K + Mean fallback) ----------\n",
        "\n",
        "def score_job_topk(required_ids: List[str], score_map: Dict[str, float], k: int = 3) -> float:\n",
        "    \"\"\"\n",
        "    Moyenne des K meilleurs scores de compétences du métier.\n",
        "    Favorise les points forts (utile si peu de réponses utilisateur).\n",
        "    \"\"\"\n",
        "    vals = [score_map.get(cid, 0.0) for cid in required_ids if cid in score_map]\n",
        "    if not vals:\n",
        "        return 0.0\n",
        "    vals.sort(reverse=True)\n",
        "    vals = vals[:k] if len(vals) >= k else vals\n",
        "    return float(np.mean(vals))\n",
        "\n",
        "def score_job_mean(required_ids: List[str], score_map: Dict[str, float]) -> float:\n",
        "    \"\"\"\n",
        "    Baseline : moyenne simple de toutes les compétences requises.\n",
        "    \"\"\"\n",
        "    vals = [score_map.get(cid, 0.0) for cid in required_ids if cid in score_map]\n",
        "    return float(np.mean(vals)) if vals else 0.0\n",
        "\n",
        "def rank_jobs(\n",
        "    jobs_df: pd.DataFrame,\n",
        "    comp_df: pd.DataFrame,\n",
        "    method: Literal[\"topk\", \"mean\"] = \"topk\",\n",
        "    top_k: int = 3\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Ajoute une colonne 'JobScore' et retourne le DataFrame trié.\n",
        "    jobs_df doit contenir : ['JobID','JobTitle','RequiredCompetencies']\n",
        "    comp_df doit contenir : ['CompetencyID','Score']\n",
        "    \"\"\"\n",
        "    score_map = dict(zip(comp_df[\"CompetencyID\"], comp_df[\"Score\"]))\n",
        "\n",
        "    if method == \"topk\":\n",
        "        scorer = lambda ids: score_job_topk(ids, score_map, k=top_k)\n",
        "    elif method == \"mean\":\n",
        "        scorer = lambda ids: score_job_mean(ids, score_map)\n",
        "    else:\n",
        "        raise ValueError(\"method must be 'topk' or 'mean'\")\n",
        "\n",
        "    ranked = jobs_df.copy()\n",
        "    ranked[\"JobScore\"] = ranked[\"RequiredCompetencies\"].apply(scorer)\n",
        "    ranked = ranked.sort_values(\"JobScore\", ascending=False).reset_index(drop=True)\n",
        "    return ranked\n"
      ]
    }
  ]
}